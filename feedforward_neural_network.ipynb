{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HuanAII/HuanAII/blob/main/feedforward_neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJ7dwEeDlLEa"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKUMZHWZliLq"
      },
      "source": [
        "# Devide configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9HvCz0elhxb"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkqKZve8lzHA"
      },
      "source": [
        "# Hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWtljeqIl368"
      },
      "source": [
        "input_size = 28*28\n",
        "hidden_size = 500\n",
        "num_classes = 10\n",
        "num_epochs = 10\n",
        "batch_size = 100\n",
        "learning_rate = 0.001"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpoR8btTmCP-"
      },
      "source": [
        "# MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35xHKxvsmGfd",
        "outputId": "6b8d839b-d580-449b-8e89-bec5d420d940"
      },
      "source": [
        "!wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
        "!tar -zxvf MNIST.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-25 06:07:08--  http://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
            "Resolving www.di.ens.fr (www.di.ens.fr)... 129.199.99.14\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.di.ens.fr/~lelarge/MNIST.tar.gz [following]\n",
            "--2021-03-25 06:07:09--  https://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/x-gzip]\n",
            "Saving to: ‘MNIST.tar.gz.1’\n",
            "\n",
            "MNIST.tar.gz.1          [      <=>           ]  33.20M  5.01MB/s    in 18s     \n",
            "\n",
            "2021-03-25 06:07:28 (1.80 MB/s) - ‘MNIST.tar.gz.1’ saved [34813078]\n",
            "\n",
            "MNIST/\n",
            "MNIST/raw/\n",
            "MNIST/raw/train-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "MNIST/raw/train-images-idx3-ubyte\n",
            "MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-images-idx3-ubyte\n",
            "MNIST/raw/train-images-idx3-ubyte.gz\n",
            "MNIST/processed/\n",
            "MNIST/processed/training.pt\n",
            "MNIST/processed/test.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2I-GSMgmLQL"
      },
      "source": [
        "#doan ma nay la mot vi du tieu chuan ve cach tai du lieu MNIST va chuan bi cac DataLoader trong Pytorch\n",
        "#Đây là một bước quan trọng tròn việc xây dụng pipeline du lieu để huấn luyện và kiểm thử mô hình học sâu\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./',\n",
        "                                           train=True,\n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "# Trong do torchvision.datasetss.MNist dung để tải và xử lý tập dữ liệu MNist\n",
        "# root là đường dẫn thư mục gốc để luu trữ hoặc tải dữ liệu\n",
        "#Train =true thì tập dữ liệu được train sẽ tải xuống còn nếu false thì tập dữ liệu kiểm thử được tải xuống\n",
        "# transforms.ToTensor() chuyển đổi định dạng thành tenso và các giá trị pixel về 0 đến 1\n",
        "#download=true : Neu du lieu chua duoc tai xuong , cờ này sẽ tự động tải lập dữ liệu về internet\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./',\n",
        "                                          train=False,\n",
        "                                          transform=transforms.ToTensor())\n",
        "\n",
        "\n",
        "# Data loader (input pipeline)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "#torch.utils.data.DataLoader su dụng để tạo pipeline du liệu và chia dữ liệu thành các batch có khả năng xáo trộn dữ liệu chia thanh\n",
        "# moi batch và shuffle=True trộn dữ liệu để giúp mô hình tránh lệ thuộc vào thứ tự dữ liêu\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "#giong voi train_loader nhung giữ nguyên thứ tự ban đầu để việc đánh giá mô hình được thực hiện nhất quán"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzLdOMQImRyn"
      },
      "source": [
        "# Fully connected neural network with one hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaPk7kLEmZih"
      },
      "source": [
        "class NeuralNet(nn.Module):\n",
        "  #ham nay dinh nghia mot lop mang nổn don gian trong pytorch sử dụng 2 tầng fully conected và hàm kích hoạt ReLu\n",
        "  # tham số nn.Module nghia la claass NeuralNet kế thừa như tự động tính toán đạo hàm\n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    #Phuong thuc init khoi tao cua lop ,, nơi idnh nghia cac lop con va mang neron se bao gom\n",
        "    #voi tham so dau vao la kich thuc input , so luong neron o tang ẩn , và số class đầu ra\n",
        "    super(NeuralNet, self).__init__()\n",
        "\n",
        "\n",
        "    self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "    #Day la tang fully connected dau tien va nho nhan kich thuoc input va chuyen doi no ra co kich thước hidden\n",
        "    self.relu = nn.ReLU()\n",
        "    #them tinh phi tuyen tinh cho mo hinh\n",
        "    self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "    #No nhan dau vao tu tang an va chuyen doi no thanh dau ra co kich thuoc num_classes\n",
        "\n",
        "  def forward(self, x): # Day la phương thức bạn xác định luồng dữ liệu qua các tầng cua rmangj nơ ron trong quá trình dự đoán đầu ra từ đầu vào\n",
        "    out = self.fc1(x) # x du qya tang dau tien\n",
        "    out = self.relu(out)#luu ket qua tu tang dau tien . Dieu nay giup mo hinh học quan hẹ phi tuyen tinh\n",
        "    out = self.fc2(out) #tao ra dau ra cuoi cùng\n",
        "\n",
        "    return out#ra ve dau ra cuoi cung cua mo hinh . dieu nay se duoc su dụng để tính toán mất mát và quy trồi ngược"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHZrQPO_3zG7"
      },
      "source": [
        "# Create model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4gUeMhb4Ixg"
      },
      "source": [
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVeAVB--4W9g"
      },
      "source": [
        "# Loss and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8kv2Ooq4Ypu"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "#CrossEntropyLoss() sẽ tính toán độ lệch chuẩn\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "#la mot do toi uu hoa su dung thuật toán SGD với tham số là chứa các tham số có thể huấn luyện mô hình"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHIgCUqxAJeu"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sipdAmisALa0",
        "outputId": "81d6d6ff-1cb5-4af4-e45a-025133ebe6cf"
      },
      "source": [
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    # Move tensor to the configured device\n",
        "    images = images.reshape(-1, input_size).to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # forward pass\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # backward and optimizer\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i+1) % 100 == 0:\n",
        "          print ('Epoch [{}/{}], Step [{}/{}], Loss: {}'\n",
        "                  .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [100/600], Loss: 2.283475875854492\n",
            "Epoch [1/10], Step [200/600], Loss: 2.2633490562438965\n",
            "Epoch [1/10], Step [300/600], Loss: 2.2417337894439697\n",
            "Epoch [1/10], Step [400/600], Loss: 2.208282232284546\n",
            "Epoch [1/10], Step [500/600], Loss: 2.18100643157959\n",
            "Epoch [1/10], Step [600/600], Loss: 2.1789002418518066\n",
            "Epoch [2/10], Step [100/600], Loss: 2.14066743850708\n",
            "Epoch [2/10], Step [200/600], Loss: 2.102980136871338\n",
            "Epoch [2/10], Step [300/600], Loss: 2.087911367416382\n",
            "Epoch [2/10], Step [400/600], Loss: 2.0868430137634277\n",
            "Epoch [2/10], Step [500/600], Loss: 2.0339438915252686\n",
            "Epoch [2/10], Step [600/600], Loss: 1.9785929918289185\n",
            "Epoch [3/10], Step [100/600], Loss: 1.9783756732940674\n",
            "Epoch [3/10], Step [200/600], Loss: 1.9386478662490845\n",
            "Epoch [3/10], Step [300/600], Loss: 1.8822011947631836\n",
            "Epoch [3/10], Step [400/600], Loss: 1.8424525260925293\n",
            "Epoch [3/10], Step [500/600], Loss: 1.8966349363327026\n",
            "Epoch [3/10], Step [600/600], Loss: 1.825413703918457\n",
            "Epoch [4/10], Step [100/600], Loss: 1.7656599283218384\n",
            "Epoch [4/10], Step [200/600], Loss: 1.7784274816513062\n",
            "Epoch [4/10], Step [300/600], Loss: 1.6237740516662598\n",
            "Epoch [4/10], Step [400/600], Loss: 1.7233467102050781\n",
            "Epoch [4/10], Step [500/600], Loss: 1.6042791604995728\n",
            "Epoch [4/10], Step [600/600], Loss: 1.6576247215270996\n",
            "Epoch [5/10], Step [100/600], Loss: 1.5544030666351318\n",
            "Epoch [5/10], Step [200/600], Loss: 1.5401396751403809\n",
            "Epoch [5/10], Step [300/600], Loss: 1.5084283351898193\n",
            "Epoch [5/10], Step [400/600], Loss: 1.4460461139678955\n",
            "Epoch [5/10], Step [500/600], Loss: 1.400965690612793\n",
            "Epoch [5/10], Step [600/600], Loss: 1.4439767599105835\n",
            "Epoch [6/10], Step [100/600], Loss: 1.2743232250213623\n",
            "Epoch [6/10], Step [200/600], Loss: 1.3297244310379028\n",
            "Epoch [6/10], Step [300/600], Loss: 1.3058665990829468\n",
            "Epoch [6/10], Step [400/600], Loss: 1.1812033653259277\n",
            "Epoch [6/10], Step [500/600], Loss: 1.25236177444458\n",
            "Epoch [6/10], Step [600/600], Loss: 1.1599111557006836\n",
            "Epoch [7/10], Step [100/600], Loss: 1.1608351469039917\n",
            "Epoch [7/10], Step [200/600], Loss: 1.1050348281860352\n",
            "Epoch [7/10], Step [300/600], Loss: 1.15165376663208\n",
            "Epoch [7/10], Step [400/600], Loss: 1.1093002557754517\n",
            "Epoch [7/10], Step [500/600], Loss: 1.1006157398223877\n",
            "Epoch [7/10], Step [600/600], Loss: 1.1341780424118042\n",
            "Epoch [8/10], Step [100/600], Loss: 1.081963300704956\n",
            "Epoch [8/10], Step [200/600], Loss: 1.0473867654800415\n",
            "Epoch [8/10], Step [300/600], Loss: 1.0522263050079346\n",
            "Epoch [8/10], Step [400/600], Loss: 1.1102885007858276\n",
            "Epoch [8/10], Step [500/600], Loss: 1.0321906805038452\n",
            "Epoch [8/10], Step [600/600], Loss: 0.889016330242157\n",
            "Epoch [9/10], Step [100/600], Loss: 0.9260755181312561\n",
            "Epoch [9/10], Step [200/600], Loss: 0.8865748643875122\n",
            "Epoch [9/10], Step [300/600], Loss: 0.9503741264343262\n",
            "Epoch [9/10], Step [400/600], Loss: 0.956565260887146\n",
            "Epoch [9/10], Step [500/600], Loss: 0.8064313530921936\n",
            "Epoch [9/10], Step [600/600], Loss: 0.9889825582504272\n",
            "Epoch [10/10], Step [100/600], Loss: 0.8861051797866821\n",
            "Epoch [10/10], Step [200/600], Loss: 0.8207511305809021\n",
            "Epoch [10/10], Step [300/600], Loss: 0.9144678711891174\n",
            "Epoch [10/10], Step [400/600], Loss: 0.7767316699028015\n",
            "Epoch [10/10], Step [500/600], Loss: 0.8441546559333801\n",
            "Epoch [10/10], Step [600/600], Loss: 0.7477918267250061\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLCQUDWyBb9t"
      },
      "source": [
        "# Test model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WglUc25OBbC6",
        "outputId": "86ce5457-9ed4-439e-85dd-c40f45eb4a72"
      },
      "source": [
        "with torch.no_grad():\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for images, labels in test_loader:\n",
        "    images = images.reshape(-1, input_size).to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print('Accuracy: {}'.format(100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 84.01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DETx5Y9aCWb5"
      },
      "source": [
        "# Save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-kgIthZCXP_"
      },
      "source": [
        "torch.save(model.state_dict(), 'NN_model.ckpt')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}